# An Emotion Recognition System Inegrated with Human Intelligence
This is a Final Year Project Submitted to Universiti Tuku Abdul Rahman. The report can be found in the repository. Please note that this is a research project thus the main focus is the report. A thesis is in progress and will be published soon.

## Abstract
Reinforcement learning (RL) is a powerful tool for solving real-world problems, but achieving high accuracy often relies on complex reward functions. Incorporating human intelligence into RL rewards enhances reliability and safety. This research focuses on improving the Two-State Q-Learning (TS-QL) approach. TS-QL uses QL to provide a second perspective to the Convolutional Neural Network (CNN) models on misclassified images by performing simple image transformation actions such as rotations. TS-QL has shown promise in enhancing the testing accuracy of a facial emotion recognition (FER) system. This research addresses four problems of TS-QL: a) the use of a single QL to learn unrelated optimal policies; b) non-optimal QL hyperparameters; c) inaccurate reward function; d) randomness in action selection. To address these problems, this research introduces Two-State Q-Learning with Human Feedback (TS-QL-HF), which aims to achieve these research objectives: a) to design specialized QL agents, each dedicated to learning distinct and unrelated optimal policies; b) to integrate, program, investigate the reinforcement learning approach with human inputs using a suitable set of hyperparameters to improve the accuracy of the FER system and the agent learning convergence rate, and provide conclusions using simulations; c) to propose, program, investigate an efficient and intelligent action selection strategy suitable for the deterministic environment in the reinforcement learning approach and provide conclusions using simulations; d) to program and investigate the effects of DQL, a reinforcement approach from previous studies in the fully deterministic environment. The improved FER system is expected to have the following deliverables: a) the multi-objective of QL is changed to a single objective; b) optimal QL hyperparameters are utilized in the QL of the FER system; c) human feedback is incorporated into the reward function of TS-QL in the FER system as TS-QL-HF; d) an intelligent and efficient action selection strategy is implemented in TS-QL-HF; e) human participation is minimized in the learning process to reduce potential human error. To evaluate the proposed approach, three experiments are conducted: a) CNN models performance comparison; b)action selection strategies performance comparison; c) QL and Double QL Performance Comparison. The experiments are run using the PyCharm IDE, and the specific settings of research scenarios, hyperparameters and CNN network architecture are showed in the results and discussions chapter. The findings of this research have practical implications in fields like healthcare, education, robotics, and marketing in dynamic environments with challenging reward design.
